# # # import pandas as pd

# # # def popularity_based_ranking(df):
# # #     # Calculate a popularity score by summing up the engagement counts
# # #     engagement_columns = ['engagement_reaction_count', 'engagement_comment_count', 'engagement_share_count']
# # #     df['popularity_score'] = df[engagement_columns].sum(axis=1)

# # #     # Sort articles by popularity score in descending order
# # #     df_sorted_by_popularity = df.sort_values(by='popularity_score', ascending=False)

# # #     # Return the sorted DataFrame or specific results as needed
# # #     return df_sorted_by_popularity[['title', 'popularity_score']].head(10)

# # import pandas as pd

# # def weighted_popularity_ranking(df):
# #     # Define weights for different engagement types
# #     weights = {
# #         'engagement_reaction_count': 1,
# #         'engagement_comment_count': 2,  # Assuming comments are more valuable
# #         'engagement_share_count': 1.5  # Shares are considered more impactful
# #     }

# #     # Calculate weighted popularity score
# #     df['weighted_popularity_score'] = (
# #         df['engagement_reaction_count'] * weights['engagement_reaction_count'] +
# #         df['engagement_comment_count'] * weights['engagement_comment_count'] +
# #         df['engagement_share_count'] * weights['engagement_share_count']
# #     )

# #     # Sort articles by weighted popularity score in descending order
# #     df_sorted_by_weighted_popularity = df.sort_values(
# #         by='weighted_popularity_score', ascending=False
# #     )

# #     # Return the sorted DataFrame or specific results as needed
# #     return df_sorted_by_weighted_popularity[['title', 'weighted_popularity_score']].head(10)

# # # Load your dataset 'articles_data.csv'
# # df = pd.read_csv('../data/articles_data.csv')

# # # Call the function to get the top articles ranked by weighted popularity score
# # top_articles_weighted = weighted_popularity_ranking(df)

# # # Display or further process the top articles ranked by weighted popularity score
# # print(top_articles_weighted)


# import pandas as pd
# from sklearn.feature_extraction.text import TfidfVectorizer

# def weighted_popularity_ranking(df):
#     # Placeholder function for weighted popularity ranking
#     # Replace this with your actual implementation for calculating popularity scores and ranking articles
#     weights = {
#         'engagement_reaction_count': 1,
#         'engagement_comment_count': 2,
#         'engagement_share_count': 2
#     }

#     # Calculate weighted popularity score
#     df['weighted_popularity_score'] = (
#         df['engagement_reaction_count'] * weights['engagement_reaction_count'] +
#         df['engagement_comment_count'] * weights['engagement_comment_count'] +
#         df['engagement_share_count'] * weights['engagement_share_count']
#     )

#     # Sort articles by weighted popularity score in descending order
#     df_sorted_by_weighted_popularity = df.sort_values(
#         by='weighted_popularity_score', ascending=False
#     )

#     # Return the sorted DataFrame or specific results as needed
#     return df_sorted_by_weighted_popularity[['title', 'weighted_popularity_score']].head(10)


# # import pandas as pd
# # from sklearn.feature_extraction.text import TfidfVectorizer

# # def tfidf_ranking(df):
# #     # Handle NaN values in 'title' column by filling them with an empty string
# #     df['title'].fillna('', inplace=True)

# #     # Extract other features along with 'title' for ranking
# #     features_to_include = ['engagement_reaction_count', 'engagement_comment_count', 'engagement_share_count']

# #     # Select desired features along with the title
# #     features_df = df[['title'] + features_to_include]

# #     # Perform TF-IDF on the 'title' column
# #     tfidf = TfidfVectorizer(max_features=5000)
# #     tfidf_matrix = tfidf.fit_transform(df['title'])

# #     # Get feature names generated by TF-IDF
# #     feature_names = tfidf.get_feature_names_out()

# #     # Calculate TF-IDF scores for each title
# #     tfidf_scores = tfidf_matrix.max(axis=1).toarray().flatten()  # Get maximum TF-IDF score for each article

# #     # Create a DataFrame with 'title', TF-IDF scores, and additional features
# #     df_tfidf = pd.DataFrame({'title': df['title'], 'tfidf_score': tfidf_scores})
# #     for feature in features_to_include:
# #         df_tfidf[feature] = features_df[feature]

# #     # Sort by TF-IDF scores and return the top 10 articles with all included features
# #     df_tfidf_sorted = df_tfidf.sort_values(by='tfidf_score', ascending=False).head(20)

# #     return df_tfidf_sorted


import pandas as pd
from sklearn.discriminant_analysis import StandardScaler
from sklearn.model_selection import train_test_split

def weighted_popularity_ranking(df):
    weights = {
        'engagement_reaction_count': 1,
        'engagement_comment_count': 2,
        'engagement_share_count': 1.5
    }

    # Calculate the weighted popularity score using vectorized operations
    df['weighted_popularity_score'] = (
        df['engagement_reaction_count'] * weights['engagement_reaction_count'] +
        df['engagement_comment_count'] * weights['engagement_comment_count'] +
        df['engagement_share_count'] * weights['engagement_share_count']
    )

    # Sort the DataFrame in descending order based on the calculated score
    df_sorted_by_weighted_popularity = df.nlargest(10, 'weighted_popularity_score')

    return df_sorted_by_weighted_popularity[['title', 'weighted_popularity_score']]


from sklearn.feature_extraction.text import TfidfVectorizer

def tfidf_ranking(df):
    df['title'].fillna('', inplace=True)

    tfidf = TfidfVectorizer(max_features=5000)
    tfidf_matrix = tfidf.fit_transform(df['title'])

    df['tfidf_score'] = tfidf_matrix.max(axis=1).toarray().flatten()

    return df[['title', 'tfidf_score']].sort_values(by='tfidf_score', ascending=False)


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Dense

def neural_network_ranking(df):
    weights = {
        'engagement_reaction_count': 1,
        'engagement_comment_count': 2,
        'engagement_share_count': 1.5
    }

    df['weighted_popularity_score'] = (
        df['engagement_reaction_count'] * weights['engagement_reaction_count'] +
        df['engagement_comment_count'] * weights['engagement_comment_count'] +
        df['engagement_share_count'] * weights['engagement_share_count']
    )

    features = ['engagement_reaction_count', 'engagement_comment_count', 'engagement_share_count']
    target = 'weighted_popularity_score'

    X = df[features]
    y = df[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Reshape input data to be 3D for LSTM input [samples, timesteps, features]
    X_train_scaled_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
    X_test_scaled_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

    model = Sequential()
    model.add(LSTM(64, input_shape=(X_train_scaled_lstm.shape[1], X_train_scaled_lstm.shape[2]), return_sequences=True))
    model.add(Dropout(0.8))  # Adding dropout for regularization
    model.add(LSTM(32))
    model.add(Dense(1, activation='relu'))

    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

    model.fit(X_train_scaled_lstm, y_train, epochs=50, batch_size=32, verbose=0, validation_split=0.2)  # Adding validation split

    loss, mae = model.evaluate(X_test_scaled_lstm, y_test, verbose=0)
    print(f"Mean Absolute Error (MAE) of LSTM model: {mae}")

    df_scaled = scaler.transform(X)
    neural_network_score = model.predict(df_scaled.reshape((df_scaled.shape[0], 1, df_scaled.shape[1])))

    df['neural_network_score_lstm'] = neural_network_score

    df_sorted_by_lstm_score = df.sort_values(by='neural_network_score_lstm', ascending=False)

    return df_sorted_by_lstm_score[['title', 'neural_network_score_lstm']]

